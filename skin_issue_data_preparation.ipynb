{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d376ac-d2a9-4cb2-9beb-a6e8e220e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from facenet_pytorch import MTCNN\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91f5f458-d2da-4544-80d2-f8e51d029433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "mtcnn = MTCNN(keep_all=False, device=device)\n",
    "from segment_anything import sam_model_registry\n",
    "sam = sam_model_registry[\"vit_b\"](checkpoint=\"sam_vit_b_01ec64.pth\").to(device)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d031419c-0c7d-43c1-add6-7cb082b2d9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "xtracting faces: 100%|████████████████████████████████████████████████████████████| 1595/1595 [08:09<00:00,  3.26it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# Initialize MTCNN\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "mtcnn = MTCNN(keep_all=False, device=device)\n",
    "\n",
    "# Input and output paths\n",
    "input_dir = 'images/skin_issues'  # root where your images are\n",
    "output_dir = 'face_extracted_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get all image paths\n",
    "image_paths = glob.glob(f\"{input_dir}/**/*.jpg\", recursive=True)\n",
    "\n",
    "# Process all images\n",
    "for path in tqdm(image_paths, desc=\"Extracting faces\"):\n",
    "    try:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        face = mtcnn(img)\n",
    "\n",
    "        if face is not None:\n",
    "            face_img = face.permute(1, 2, 0).int().numpy().astype('uint8')\n",
    "            face_pil = Image.fromarray(face_img)\n",
    "            filename = os.path.basename(path)\n",
    "            face_pil.save(os.path.join(output_dir, filename))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cb23af5-c832-49a3-b13e-e14a4036569f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "xtracting faces: 100%|████████████████████████████████████████████████████████████| 1595/1595 [07:54<00:00,  3.36it/s]"
     ]
    }
   ],
   "source": [
    "# YOLO class IDs\n",
    "\n",
    "def extract_faces(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    all_images = glob.glob(f\"{input_dir}/**/*.jpg\", recursive=True)\n",
    "\n",
    "    for img_path in tqdm(all_images, desc=\"Extracting faces\"):\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            face = mtcnn(img)\n",
    "            if face is None:\n",
    "                continue\n",
    "            np_img = face.permute(1, 2, 0).cpu().numpy()\n",
    "            np_img = ((np_img + 1) * 127.5).astype(np.uint8)\n",
    "            rel_path = os.path.relpath(img_path, input_dir)\n",
    "            save_path = os.path.join(output_dir, rel_path)\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "            Image.fromarray(np_img).save(save_path)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Step 1: Extract faces to a separate folder\n",
    "    extract_faces(input_dir='images/skin_issues', output_dir='faces_dataset')\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a5f35-3c83-4b9c-9d35-2b1ad6605492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train set:   8%|███▊                                               | 80/1055 [10:08:54<98:49:12, 364.87s/it]"
     ]
    }
   ],
   "source": [
    "def process_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        np_img = np.array(img)\n",
    "        masks = mask_generator.generate(np_img)\n",
    "        h, w = np_img.shape[:2]\n",
    "        yolo_annotations = []\n",
    "        for m in masks:\n",
    "            mask = m['segmentation']\n",
    "            region = cv2.bitwise_and(np_img, np_img, mask=mask.astype(np.uint8))\n",
    "            if is_wrinkle(np_img, mask):\n",
    "                yolo = mask_to_yolo(mask, CLASS_MAP['wrinkles'], w, h)\n",
    "                if yolo: yolo_annotations.append(yolo)\n",
    "            if is_redness(np_img, mask):\n",
    "                yolo = mask_to_yolo(mask, CLASS_MAP['redness'], w, h)\n",
    "                if yolo: yolo_annotations.append(yolo)\n",
    "            if is_dryness(np_img, mask):\n",
    "                yolo = mask_to_yolo(mask, CLASS_MAP['dryness'], w, h)\n",
    "                if yolo: yolo_annotations.append(yolo)\n",
    "\n",
    "        acne_label = get_acne_label(image_path)\n",
    "        if acne_label is not None:\n",
    "            yolo = f\"{acne_label} 0.5 0.5 1.0 1.0\"\n",
    "            yolo_annotations.append(yolo)\n",
    "\n",
    "        return np_img, yolo_annotations\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "def prepare_dataset(image_root='faces_dataset', output_root='yolo_dataset', split_ratio=0.8):\n",
    "    all_images = glob.glob(f\"{image_root}/**/*.jpg\", recursive=True)\n",
    "    random.shuffle(all_images)\n",
    "    split_idx = int(len(all_images) * split_ratio)\n",
    "    train_imgs, val_imgs = all_images[:split_idx], all_images[split_idx:]\n",
    "\n",
    "    for mode, images in zip(['train', 'val'], [train_imgs, val_imgs]):\n",
    "        img_dir = os.path.join(output_root, 'images', mode)\n",
    "        lbl_dir = os.path.join(output_root, 'labels', mode)\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "        os.makedirs(lbl_dir, exist_ok=True)\n",
    "\n",
    "        for img_path in tqdm(images, desc=f\"Processing {mode} set\"):\n",
    "            cropped_img, annotations = process_image(img_path)\n",
    "            if cropped_img is None or not annotations:\n",
    "                continue\n",
    "\n",
    "            base = os.path.basename(img_path)\n",
    "            base = os.path.splitext(base)[0]\n",
    "            out_img_path = os.path.join(img_dir, base + \".jpg\")\n",
    "            out_lbl_path = os.path.join(lbl_dir, base + \".txt\")\n",
    "\n",
    "            Image.fromarray(cropped_img).save(out_img_path)\n",
    "            with open(out_lbl_path, 'w') as f:\n",
    "                f.write(\"\\n\".join(annotations))\n",
    "\n",
    "    # Write dataset.yaml\n",
    "    with open(os.path.join(output_root, 'dataset.yaml'), 'w') as f:\n",
    "        f.write(\"\"\"\n",
    "path: ./yolo_dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "names:\n",
    "  0: wrinkles\n",
    "  1: redness\n",
    "  2: dryness\n",
    "  3: acne_Level_0\n",
    "  4: acne_Level_1\n",
    "  5: acne_Level_2\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   # Step 2: Label the face images\n",
    "    prepare_dataset(image_root='faces_dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb205d-9b3b-47e2-9594-17027fe2f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        np_img = np.array(img)\n",
    "        masks = mask_generator.generate(np_img)\n",
    "        h, w = np_img.shape[:2]\n",
    "        yolo_annotations = []\n",
    "        for m in masks:\n",
    "            mask = m['segmentation']\n",
    "            region = cv2.bitwise_and(np_img, np_img, mask=mask.astype(np.uint8))\n",
    "            if is_wrinkle(np_img, mask):\n",
    "                yolo = mask_to_yolo(mask, CLASS_MAP['wrinkles'], w, h)\n",
    "                if yolo: yolo_annotations.append(yolo)\n",
    "            if is_redness(np_img, mask):\n",
    "                yolo = mask_to_yolo(mask, CLASS_MAP['redness'], w, h)\n",
    "                if yolo: yolo_annotations.append(yolo)\n",
    "            if is_dryness(np_img, mask):\n",
    "                yolo = mask_to_yolo(mask, CLASS_MAP['dryness'], w, h)\n",
    "                if yolo: yolo_annotations.append(yolo)\n",
    "\n",
    "        acne_label = get_acne_label(image_path)\n",
    "        if acne_label is not None:\n",
    "            yolo = f\"{acne_label} 0.5 0.5 1.0 1.0\"\n",
    "            yolo_annotations.append(yolo)\n",
    "\n",
    "        return np_img, yolo_annotations\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "def prepare_dataset(image_root='faces_dataset', output_root='yolo_dataset', split_ratio=0.8):\n",
    "    all_images = glob.glob(f\"{image_root}/**/*.jpg\", recursive=True)\n",
    "    random.shuffle(all_images)\n",
    "    split_idx = int(len(all_images) * split_ratio)\n",
    "    train_imgs, val_imgs = all_images[:split_idx], all_images[split_idx:]\n",
    "\n",
    "    for mode, images in zip(['train', 'val'], [train_imgs, val_imgs]):\n",
    "        img_dir = os.path.join(output_root, 'images', mode)\n",
    "        lbl_dir = os.path.join(output_root, 'labels', mode)\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "        os.makedirs(lbl_dir, exist_ok=True)\n",
    "\n",
    "        for img_path in tqdm(images, desc=f\"Processing {mode} set\"):\n",
    "            cropped_img, annotations = process_image(img_path)\n",
    "            if cropped_img is None or not annotations:\n",
    "                continue\n",
    "\n",
    "            base = os.path.basename(img_path)\n",
    "            base = os.path.splitext(base)[0]\n",
    "            out_img_path = os.path.join(img_dir, base + \".jpg\")\n",
    "            out_lbl_path = os.path.join(lbl_dir, base + \".txt\")\n",
    "\n",
    "            Image.fromarray(cropped_img).save(out_img_path)\n",
    "            with open(out_lbl_path, 'w') as f:\n",
    "                f.write(\"\\n\".join(annotations))\n",
    "\n",
    "    # Write dataset.yaml\n",
    "    with open(os.path.join(output_root, 'dataset.yaml'), 'w') as f:\n",
    "        f.write(\"\"\"\n",
    "path: ./yolo_dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "names:\n",
    "  0: wrinkles\n",
    "  1: redness\n",
    "  2: dryness\n",
    "  3: acne_Level_0\n",
    "  4: acne_Level_1\n",
    "  5: acne_Level_2\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   # Step 2: Label the face images\n",
    "    prepare_dataset(image_root='faces_dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d901c-3169-4cc9-9e77-1333e667159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def save_processed(img_path_and_data, img_dir, lbl_dir):\n",
    "    img_path, result = img_path_and_data\n",
    "    cropped_img, annotations = result\n",
    "    if cropped_img is None or not annotations:\n",
    "        return\n",
    "\n",
    "    base = os.path.basename(img_path)\n",
    "    base = os.path.splitext(base)[0]\n",
    "    out_img_path = os.path.join(img_dir, base + \".jpg\")\n",
    "    out_lbl_path = os.path.join(lbl_dir, base + \".txt\")\n",
    "\n",
    "    Image.fromarray(cropped_img).save(out_img_path)\n",
    "    with open(out_lbl_path, 'w') as f:\n",
    "        f.write(\"\\n\".join(annotations))\n",
    "\n",
    "def prepare_dataset(image_root='faces_dataset', output_root='yolo_dataset', split_ratio=0.8):\n",
    "    all_images = glob.glob(f\"{image_root}/**/*.jpg\", recursive=True)\n",
    "    random.shuffle(all_images)\n",
    "    split_idx = int(len(all_images) * split_ratio)\n",
    "    train_imgs, val_imgs = all_images[:split_idx], all_images[split_idx:]\n",
    "\n",
    "    for mode, images in zip(['train', 'val'], [train_imgs, val_imgs]):\n",
    "        img_dir = os.path.join(output_root, 'images', mode)\n",
    "        lbl_dir = os.path.join(output_root, 'labels', mode)\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "        os.makedirs(lbl_dir, exist_ok=True)\n",
    "\n",
    "        print(f\"Processing {mode} set with {len(images)} images using {cpu_count()} processes...\")\n",
    "        with Pool(processes=cpu_count()) as pool:\n",
    "            results = list(tqdm(pool.imap(process_image, images), total=len(images), desc=f\"Processing {mode}\"))\n",
    "            for img_path, result in zip(images, results):\n",
    "                save_processed((img_path, result), img_dir, lbl_dir)\n",
    "\n",
    "    # Write dataset.yaml\n",
    "    with open(os.path.join(output_root, 'dataset.yaml'), 'w') as f:\n",
    "        f.write(\"\"\"\n",
    "path: ./yolo_dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "names:\n",
    "  0: wrinkles\n",
    "  1: redness\n",
    "  2: dryness\n",
    "  3: acne_Level_0\n",
    "  4: acne_Level_1\n",
    "  5: acne_Level_2\n",
    "\"\"\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import multiprocessing\n",
    "    multiprocessing.set_start_method('spawn')  # Important for Windows or Colab!\n",
    "    prepare_dataset(image_root='faces_dataset')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
